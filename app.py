import streamlit as st
import pandas as pd
import sqlite3
from datetime import datetime
import os
import plotly.express as px
import re
# <<< ìˆ˜ì •ëœ ë¶€ë¶„: ìœ íŠœë¸Œ API ì—°ë™ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ >>>
from dotenv import load_dotenv
from googleapiclient.discovery import build

# --- 1. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë° ê´€ë¦¬ ---
DB_FILE = "recipe_service.db"

def setup_database():
    """ì•± ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ í˜¸ì¶œë˜ì–´ DB ë° í…Œì´ë¸”, ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    conn = sqlite3.connect(DB_FILE)
    cursor = conn.cursor()

    # í…Œì´ë¸” ìƒì„± (ê¸°ì¡´ + ì˜ì–‘ì„±ë¶„ ê³„ì‚°ê¸°ìš© í…Œì´ë¸” ì¶”ê°€)
    cursor.execute('''CREATE TABLE IF NOT EXISTS recipes (RECIPE_ID INTEGER PRIMARY KEY, RECIPE_NM_KO TEXT, NATION_NM TEXT, TY_NM TEXT, CALORIE REAL, PROTEIN REAL, FAT REAL, CARBOHYDRATE REAL)''')
    cursor.execute('''CREATE TABLE IF NOT EXISTS ingredients (INGREDIENT_ID INTEGER PRIMARY KEY AUTOINCREMENT, RECIPE_ID INTEGER, INGREDIENT_NAME TEXT, FOREIGN KEY (RECIPE_ID) REFERENCES recipes (RECIPE_ID))''')
    cursor.execute('''CREATE TABLE IF NOT EXISTS steps (STEP_ID INTEGER PRIMARY KEY AUTOINCREMENT, RECIPE_ID INTEGER, STEP_DESCRIPTION TEXT, FOREIGN KEY (RECIPE_ID) REFERENCES recipes (RECIPE_ID))''')
    cursor.execute('''CREATE TABLE IF NOT EXISTS search_logs (LOG_ID INTEGER PRIMARY KEY AUTOINCREMENT, KEYWORD TEXT, SEARCH_TIME TEXT)''')
    cursor.execute('''CREATE TABLE IF NOT EXISTS dwell_time_logs (LOG_ID INTEGER PRIMARY KEY AUTOINCREMENT, RECIPE_ID INTEGER, RECIPE_NM_KO TEXT, DWELL_SECONDS REAL, LOG_TIME TEXT)''')
    cursor.execute('''CREATE TABLE IF NOT EXISTS ingredient_nutrition (INGREDIENT_NAME TEXT PRIMARY KEY, CALORIE_PER_100G REAL, PROTEIN_PER_100G REAL, FAT_PER_100G REAL, CARBS_PER_100G REAL)''')

    # ìƒ˜í”Œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì‚½ì…
    if cursor.execute("SELECT COUNT(*) FROM recipes").fetchone()[0] == 0:
        recipe_data = [{'RECIPE_ID': 1, 'RECIPE_NM_KO': 'ë‹­ë³¶ìŒíƒ•', 'NATION_NM': 'í•œì‹', 'TY_NM': 'ë©”ì¸ìš”ë¦¬', 'CALORIE': 550, 'PROTEIN': 45, 'FAT': 25, 'CARBOHYDRATE': 35},
                       {'RECIPE_ID': 2, 'RECIPE_NM_KO': 'ê¹€ì¹˜ì°Œê°œ', 'NATION_NM': 'í•œì‹', 'TY_NM': 'ì°Œê°œ', 'CALORIE': 350, 'PROTEIN': 25, 'FAT': 18, 'CARBOHYDRATE': 15},
                       {'RECIPE_ID': 3, 'RECIPE_NM_KO': 'í† ë§ˆí†  ìŠ¤íŒŒê²Œí‹°', 'NATION_NM': 'ì–‘ì‹', 'TY_NM': 'ë©´ìš”ë¦¬', 'CALORIE': 650, 'PROTEIN': 20, 'FAT': 15, 'CARBOHYDRATE': 80}]
        pd.DataFrame(recipe_data).to_sql('recipes', conn, if_exists='append', index=False)

    if cursor.execute("SELECT COUNT(*) FROM ingredient_nutrition").fetchone()[0] == 0:
        nutrition_data = [
            ('ë‹­ê³ ê¸°', 230, 27, 14, 0), ('ê°ì', 77, 2, 0.1, 17), ('ì–‘íŒŒ', 40, 1.1, 0.1, 9),
            ('ê¹€ì¹˜', 34, 2, 0.5, 5), ('ë¼ì§€ê³ ê¸°', 242, 27, 14, 0), ('í† ë§ˆí†  ì†ŒìŠ¤', 29, 1.3, 0.2, 5),
            ('ìŠ¤íŒŒê²Œí‹°ë©´', 158, 5.5, 0.8, 31), ('ë‘ë¶€', 76, 8, 4.8, 1.9), ('ì–‘ìƒì¶”', 15, 0.9, 0.2, 3),
            ('ê³„ë€', 155, 13, 11, 1.1), ('ìŒ€ë°¥', 130, 2.7, 0.3, 28)
        ]
        cursor.executemany("INSERT INTO ingredient_nutrition VALUES (?, ?, ?, ?, ?)", nutrition_data)
    
    conn.commit()
    conn.close()

# --- 2. í—¬í¼ í•¨ìˆ˜ (DB ì¿¼ë¦¬, ë¡œê·¸, API) ---
def db_query(query, params=()):
    with sqlite3.connect(DB_FILE) as conn:
        return pd.read_sql_query(query, conn, params=params)

def end_current_view_log(): # ì²´ë¥˜ì‹œê°„ ê¸°ë¡ í•¨ìˆ˜
    if 'current_view' in st.session_state and st.session_state.current_view:
        dwell_time = (datetime.now() - st.session_state.current_view['start_time']).total_seconds()
        if dwell_time > 3:
            with sqlite3.connect(DB_FILE) as conn:
                conn.execute("INSERT INTO dwell_time_logs (RECIPE_ID, RECIPE_NM_KO, DWELL_SECONDS, LOG_TIME) VALUES (?, ?, ?, ?)",
                             (st.session_state.current_view['id'], st.session_state.current_view['name'], round(dwell_time, 2), datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
        st.session_state.current_view = None

def search_by_recipe_name(keyword, nation):
    query = "SELECT RECIPE_ID, RECIPE_NM_KO FROM recipes WHERE RECIPE_NM_KO LIKE ? AND (? = 'ì „ì²´' OR NATION_NM = ?)"
    return db_query(query, (f'%{keyword}%', nation, nation))

###########################################################################
# --- ì˜ì–‘ì„±ë¶„ ê³„ì‚°ê¸° í•¨ìˆ˜ --- @@@@
CSV_FILE_PATH = 'nutrition_info.CSV'
SEARCH_COLUMN = 'ì‹í’ˆëª…'
NUTRITION_COLUMNS = ['ì—ë„ˆì§€', 'íƒ„ìˆ˜í™”ë¬¼', 'ë‹¨ë°±ì§ˆ', 'ì§€ë°© ', 'ë‹¹ë¥˜']

@st.cache_data
def load_nutrition_data(file_path):
    """CSVì—ì„œ ì˜ì–‘ì„±ë¶„ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    try:
        df = pd.read_csv(file_path, encoding='utf-8-sig')
        df = df.iloc[2:].reset_index(drop=True) # ë¶ˆí•„ìš”í•œ í–‰ ì œê±°
        # ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜, ë³€í™˜ ë¶ˆê°€ ì‹œ 0ìœ¼ë¡œ ì²˜ë¦¬
        for col in NUTRITION_COLUMNS:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
                df[col] = df[col].fillna(0)
        return df
    except FileNotFoundError:
        st.error(f"ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

@st.cache_data
def build_keywords(df):
    """ë°ì´í„°í”„ë ˆì„ì—ì„œ ê²€ìƒ‰ì„ ìœ„í•œ í‚¤ì›Œë“œì™€ ë™ì˜ì–´ ì‚¬ì „ì„ ë§Œë“­ë‹ˆë‹¤."""
    all_food_names = df[SEARCH_COLUMN].dropna().unique()
    keywords = set(p for name in all_food_names for p in re.split(r'[,\s]+', name) if p)
    synonyms = {'ë‹­': 'ë‹­ê³ ê¸°', 'ë¼ì§€': 'ë¼ì§€ê³ ê¸°', 'ì†Œ': 'ì‡ ê³ ê¸°', 'ê³„ë€': 'ë‹¬ê±€', 'ìƒ': 'ìƒê²ƒ', 'êµ¬ìš´': 'êµ¬ì´', 'ì‚¶ì€': 'ì‚¶ê¸°', 'íŠ€ê¸´': 'íŠ€ê¹€', 'ê°€ìŠ´': 'ê°€ìŠ´ì‚´'}
    return keywords, synonyms

def find_best_match(search_query: str, df: pd.DataFrame, keywords: set, synonyms: dict):
    """ì‚¬ìš©ì ì…ë ¥ì— ê°€ì¥ ì˜ ë§ëŠ” í•­ëª©ì„ ì ìˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤."""
    search_query_parts = set(re.split(r'[,\s]+', search_query))
    extracted_keywords = keywords.intersection(search_query_parts)
    
    normalized_keywords = {synonyms.get(key, key) for key in extracted_keywords}
    for syn, real_key in synonyms.items():
        if syn in search_query:
            normalized_keywords.add(real_key)

    if not normalized_keywords:
        return None

    def calculate_score(row_food_name):
        return sum(1 for key in normalized_keywords if key in row_food_name)

    df['match_score'] = df[SEARCH_COLUMN].apply(calculate_score)
    relevant_results = df[df['match_score'] > 0]

    if relevant_results.empty:
        return None

    # ìµœëŒ€ ì ìˆ˜ë¥¼ ê°€ì§„ í–‰ ì°¾ê¸°
    max_score = relevant_results['match_score'].max()
    best_match_row = relevant_results[relevant_results['match_score'] == max_score].iloc[0]
    return best_match_row

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'current_view' not in st.session_state: st.session_state.current_view = None
if 'calculator_ingredients' not in st.session_state: st.session_state.calculator_ingredients = []

#################################################################################



# .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()
api_key = os.getenv("YOUTUBE_API_KEY")

# <<< ì‹¤ì œ YouTube API í˜¸ì¶œ í•¨ìˆ˜ >>>
def get_youtube_videos(query, max_results=2):
    st.info(f"ğŸ” ìœ íŠœë¸Œì—ì„œ '{query}'(ì„)ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")

    if not api_key:
        st.error("â— ìœ íŠœë¸Œ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return []

    try:
        # ìœ íŠœë¸Œ API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        youtube = build("youtube", "v3", developerKey=api_key)
        
        # ê²€ìƒ‰ ìš”ì²­
        request = youtube.search().list(
            part="snippet",
            q=f"{query} ë ˆì‹œí”¼",  # ê²€ìƒ‰ì–´ë¥¼ ë” êµ¬ì²´ì ìœ¼ë¡œ
            maxResults=max_results,
            type="video",
            order="viewCount" # ì¡°íšŒìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        )
        response = request.execute()

        videos = []
        for item in response.get("items", []):
            video = {
                "title": item["snippet"]["title"],
                "video_id": item["id"]["videoId"]
            }
            videos.append(video)
        
        if not videos:
            st.warning("ê´€ë ¨ ìœ íŠœë¸Œ ì˜ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return videos

    except Exception as e:
        st.error(f"â— ìœ íŠœë¸Œ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return []

def get_youtube_trends(): # ìœ íŠœë¸Œ íŠ¸ë Œë“œ ë¶„ì„ (ê°€ìƒì„)
    trends_df = pd.DataFrame({
        'trend_keyword': ['ë§ˆë¼íƒ•', 'íƒ•í›„ë£¨', 'ì•½ê³¼', 'ì œë¡œ ìŒë£Œ', 'ë‹¨ë°±ì§ˆ ì‰ì´í¬'],
        'search_volume': [1200, 1150, 980, 850, 700]
    })
    return trends_df

# <<< ì‹¤ì œ ê³µê³µë°ì´í„° ë ˆì‹œí”¼ API í˜¸ì¶œ í•¨ìˆ˜ >>>

# <<< ì‹¤ì œ  API í˜¸ì¶œ í•¨ìˆ˜ >>>

# --- 3. Streamlit UI ---
st.set_page_config(layout="wide", page_title="ë ˆì‹œí”¼ ì¶”ì²œ ì„œë¹„ìŠ¤")
setup_database()

if 'current_view' not in st.session_state:
    st.session_state.current_view = None

st.title("ï¿½ï¿½ ë ˆì‹œí”¼ ì¶”ì²œ ë° ë¶„ì„ ì„œë¹„ìŠ¤")

tab1, tab2, tab3 = st.tabs(["ğŸ“Š ë ˆì‹œí”¼ ê²€ìƒ‰", "ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„", "ğŸ§® ì˜ì–‘ì„±ë¶„ ê³„ì‚°ê¸°"])

# --- íƒ­ 1: ë ˆì‹œí”¼ ê²€ìƒ‰ ---
with tab1:
    col1, col2 = st.columns([0.4, 0.6])
    with col1:
        st.subheader("1. ê²€ìƒ‰ ìœ í˜• ì„ íƒ")
        search_mode = st.radio("ì–´ë–¤ ë ˆì‹œí”¼ë¥¼ ì°¾ìœ¼ì‹œë‚˜ìš”?", ["ì¼ë°˜ ê²€ìƒ‰ (ìŒì‹/ì¬ë£Œëª…)", "í…Œë§ˆë³„ ê²€ìƒ‰ (ë¹„ê±´, ë‹¤ì´ì–´íŠ¸ ë“±)"], horizontal=True)
        st.divider()

        # ê²€ìƒ‰ ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
        if search_mode == "ì¼ë°˜ ê²€ìƒ‰ (ìŒì‹/ì¬ë£Œëª…)":
            st.subheader("2. ê²€ìƒ‰ ì¡°ê±´ ì…ë ¥")
            keyword = st.text_input("ìŒì‹ëª… ë˜ëŠ” ì¬ë£Œëª…ì„ ì…ë ¥í•˜ì„¸ìš”:")
            nation_filter = st.selectbox("ìŒì‹ ì¢…ë¥˜", ["ì „ì²´", "í•œì‹", "ì¤‘ì‹", "ì–‘ì‹"])

            if st.button("ë ˆì‹œí”¼ ê²€ìƒ‰", key="normal_search"):
                end_current_view_log()
                if keyword:
                    with sqlite3.connect(DB_FILE) as conn:
                         conn.execute("INSERT INTO search_logs (KEYWORD, SEARCH_TIME) VALUES (?, ?)", (keyword, datetime.now().strftime('%Y-%m-%d %H:%M:%S')))
                    st.session_state.search_results = search_by_recipe_name(keyword, nation_filter)
                    st.session_state.selected_recipe_id = None
                else:
                    st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            if 'search_results' in st.session_state and not st.session_state.search_results.empty:
                st.subheader("3. ê²€ìƒ‰ ê²°ê³¼")
                recipe_options = pd.Series(st.session_state.search_results.RECIPE_NM_KO.values, index=st.session_state.search_results.RECIPE_ID).to_dict()
                selected_recipe_id = st.selectbox("ë ˆì‹œí”¼ ì„ íƒ:", options=recipe_options.keys(), format_func=lambda x: recipe_options.get(x, "ì„ íƒ"), index=None)
                
                if selected_recipe_id:
                    if not st.session_state.current_view or st.session_state.current_view['id'] != selected_recipe_id:
                        end_current_view_log()
                        st.session_state.current_view = {'id': selected_recipe_id, 'name': recipe_options[selected_recipe_id], 'start_time': datetime.now()}
                    st.session_state.selected_recipe_id = selected_recipe_id

        if search_mode == "í…Œë§ˆë³„ ê²€ìƒ‰ (ë¹„ê±´, ë‹¤ì´ì–´íŠ¸ ë“±)":
            st.subheader("2. í…Œë§ˆ ì„ íƒ")
            theme_keyword = st.selectbox("ì›í•˜ëŠ” í…Œë§ˆë¥¼ ì„ íƒí•˜ì„¸ìš”.", ["ë¹„ê±´ ìš”ë¦¬", "ê³ ë‹¨ë°±ì§ˆ ë‹¤ì´ì–´íŠ¸", "ì €íƒ„ìˆ˜í™”ë¬¼ ì‹ë‹¨"])
            if st.button("í…Œë§ˆë¡œ ì˜ìƒ ê²€ìƒ‰", key="theme_search"):
                st.session_state.theme_videos = get_youtube_videos(theme_keyword, max_results=5)
                st.session_state.selected_recipe_id = None
                end_current_view_log()

    with col2:
        st.subheader("ê²°ê³¼ ë³´ê¸°")
        if 'selected_recipe_id' in st.session_state and st.session_state.selected_recipe_id:
            info = db_query("SELECT * FROM recipes WHERE RECIPE_ID = ?", (st.session_state.selected_recipe_id,)).iloc[0]
            st.markdown(f"### ğŸ½ï¸ {info['RECIPE_NM_KO']}")
            # ìœ íŠœë¸Œ ì˜ìƒ ì¶œë ¥
            videos = get_youtube_videos(info['RECIPE_NM_KO'])
            if videos:
                for video in videos:
                    st.write(f"**{video['title']}**")
                    st.video(f"https://www.youtube.com/watch?v={video['video_id']}")

        elif 'theme_videos' in st.session_state and st.session_state.theme_videos:
             st.markdown(f"### ğŸ¥ '{theme_keyword}' ì¶”ì²œ ìœ íŠœë¸Œ ì˜ìƒ")
             for video in st.session_state.theme_videos:
                 st.write(f"**{video['title']}**")
                 st.video(f"https://www.youtube.com/watch?v={video['video_id']}")
        else:
            st.info("ì™¼ìª½ì—ì„œ ë ˆì‹œí”¼ë¥¼ ê²€ìƒ‰í•˜ê±°ë‚˜ í…Œë§ˆë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

# --- íƒ­ 2: íŠ¸ë Œë“œ ë¶„ì„ ---
with tab2:
    st.header("íŠ¸ë Œë“œ ë°ì´í„° ë¶„ì„")
    st.subheader("1. ë‚´ë¶€ ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ ë¶„ì„")
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**í‚¤ì›Œë“œë³„ ê²€ìƒ‰ ë¹ˆë„**")
        keyword_df = db_query("SELECT KEYWORD, COUNT(*) as count FROM search_logs GROUP BY KEYWORD ORDER BY count DESC")
        st.dataframe(keyword_df, use_container_width=True)
        if not keyword_df.empty:
            fig1 = px.bar(keyword_df.head(10), x='KEYWORD', y='count', title='ì¸ê¸° ê²€ìƒ‰ì–´ TOP 10')
            st.plotly_chart(fig1, use_container_width=True)
            
    with col2:
        st.markdown("**ë ˆì‹œí”¼ë³„ í‰ê·  ì²´ë¥˜ ì‹œê°„(ì´ˆ)**")
        dwell_df = db_query("SELECT RECIPE_NM_KO, ROUND(AVG(DWELL_SECONDS), 2) as avg_dwell_sec FROM dwell_time_logs GROUP BY RECIPE_ID, RECIPE_NM_KO ORDER BY avg_dwell_sec DESC")
        st.dataframe(dwell_df, use_container_width=True)
        if not dwell_df.empty:
            fig2 = px.bar(dwell_df.head(10), x='RECIPE_NM_KO', y='avg_dwell_sec', title='í‰ê·  ì²´ë¥˜ ì‹œê°„ì´ ê¸´ ë ˆì‹œí”¼ TOP 10')
            st.plotly_chart(fig2, use_container_width=True)

    # st.divider()
    # st.subheader("2. ìœ íŠœë¸Œ API í™œìš© íŠ¸ë Œë“œ ë¶„ì„ (ê°€ìƒ)")
    # yt_trends = get_youtube_trends()
    # st.markdown("ìµœê·¼ ëŒ€ì¤‘ì ìœ¼ë¡œ ê´€ì‹¬ìˆëŠ” ìŒì‹ í‚¤ì›Œë“œì…ë‹ˆë‹¤. (ì£¼ê¸°ì  ìˆ˜ì§‘ ë°ì´í„° ì˜ˆì‹œ)")
    # st.dataframe(yt_trends, use_container_width=True)
    # fig3 = px.pie(yt_trends, names='trend_keyword', values='search_volume', title='ìœ íŠœë¸Œ ì¸ê¸° ìŒì‹ í‚¤ì›Œë“œ ì ìœ ìœ¨')
    # st.plotly_chart(fig3, use_container_width=True)

# --- íƒ­ 3: ì˜ì–‘ì„±ë¶„ ê³„ì‚°ê¸° ---
with tab3:
    st.header("ì˜ì–‘ì„±ë¶„ ê³„ì‚°ê¸°")
    st.info("ì¬ë£Œëª…ì„ ê²€ìƒ‰í•˜ì—¬ ëª©ë¡ì— ì¶”ê°€í•˜ê³  ê·¸ë¨(g)ì„ ì…ë ¥í•˜ë©´ ì´ ì˜ì–‘ì„±ë¶„ì´ ê³„ì‚°ë©ë‹ˆë‹¤.")

    main_df = load_nutrition_data(CSV_FILE_PATH)

    if main_df is not None:
        keyword_vocab, synonym_map = build_keywords(main_df)

        # 1. ì¬ë£Œ ê²€ìƒ‰ ë° ì¶”ê°€
        search_query = st.text_input("ì¬ë£Œëª…ì„ ê²€ìƒ‰í•˜ì„¸ìš” (ì˜ˆ: 'ì‚¶ì€ê³„ë€'):")
        
        if search_query:
            best_match = find_best_match(search_query, main_df.copy(), keyword_vocab, synonym_map)
            if best_match is not None:
                st.write(f"**ê²€ìƒ‰ ê²°ê³¼:** {best_match[SEARCH_COLUMN]}")
                if st.button("ëª©ë¡ì— ì¶”ê°€í•˜ê¸°", key=f"add_{search_query}"):
                    # ì¤‘ë³µ ì¶”ê°€ ë°©ì§€
                    if not any(d['name'] == best_match[SEARCH_COLUMN] for d in st.session_state.calculator_ingredients):
                        st.session_state.calculator_ingredients.append({
                            'name': best_match[SEARCH_COLUMN],
                            'nutrients_per_100g': best_match[NUTRITION_COLUMNS],
                            'grams': 100  # ê¸°ë³¸ê°’ 100g
                        })
                    else:
                        st.warning("ì´ë¯¸ ëª©ë¡ì— ìˆëŠ” í•­ëª©ì…ë‹ˆë‹¤.")
            else:
                st.warning("ì¼ì¹˜í•˜ëŠ” í•­ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        st.divider()

        # 2. ì„ íƒëœ ì¬ë£Œ ëª©ë¡ ë° ì´ ì˜ì–‘ì„±ë¶„ ê³„ì‚°
        total_nutrition = {col: 0.0 for col in NUTRITION_COLUMNS}
        
        if st.session_state.calculator_ingredients:
            st.subheader("ê³„ì‚° ëª©ë¡")
            
            # ëª©ë¡ì˜ ê° í•­ëª©ì„ ì‚­ì œí•˜ê¸° ìœ„í•œ ë¡œì§
            indices_to_remove = []
            for i, item in enumerate(st.session_state.calculator_ingredients):
                col1, col2, col3 = st.columns([4, 2, 1])
                with col1:
                    st.write(item['name'])
                with col2:
                    item['grams'] = st.number_input(f"ê·¸ë¨(g)", min_value=0, value=item['grams'], step=10, key=f"grams_{i}")
                with col3:
                    if st.button("ì‚­ì œ", key=f"del_{i}"):
                        indices_to_remove.append(i)

                # ì´ ì˜ì–‘ì„±ë¶„ ê³„ì‚°
                for col in NUTRITION_COLUMNS:
                    total_nutrition[col] += (item['nutrients_per_100g'][col] * item['grams'] / 100)

            # ì‚­ì œí•  í•­ëª©ë“¤ì„ ì—­ìˆœìœ¼ë¡œ ì œê±°
            for i in sorted(indices_to_remove, reverse=True):
                st.session_state.calculator_ingredients.pop(i)
                st.rerun()

            st.divider()
            st.subheader("ì´ ì˜ì–‘ì„±ë¶„ í•©ê³„")
            kpi_cols = st.columns(5)
            kpi_cols[0].metric("ì´ ì—ë„ˆì§€ (kcal)", f"{total_nutrition.get('ì—ë„ˆì§€', 0):.1f}")
            kpi_cols[1].metric("ì´ íƒ„ìˆ˜í™”ë¬¼ (g)", f"{total_nutrition.get('íƒ„ìˆ˜í™”ë¬¼', 0):.1f}")
            kpi_cols[2].metric("ì´ ë‹¨ë°±ì§ˆ (g)", f"{total_nutrition.get('ë‹¨ë°±ì§ˆ', 0):.1f}")
            kpi_cols[3].metric("ì´ ì§€ë°© (g)", f"{total_nutrition.get('ì§€ë°© ', 0):.1f}")
            kpi_cols[4].metric("ì´ ë‹¹ë¥˜ (g)", f"{total_nutrition.get('ë‹¹ë¥˜', 0):.1f}")
        else:
            st.write("ê³„ì‚°í•  ì¬ë£Œë¥¼ ê²€ìƒ‰í•˜ì—¬ ì¶”ê°€í•´ì£¼ì„¸ìš”.") 